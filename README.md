# C++ Unit Test Generator using Ollama ğŸš€

This project is part of the **Keploy API Fellowship - Day 5 Assignment**.

It demonstrates how to use **Ollama** (running open-source Large Language Models locally) to automatically generate **unit tests** for a C++ application and optionally refine them based on feedback.

---

## ğŸ“ Project Overview

- âœ… Takes existing C++ source code (`main.cpp`)
- âœ… Uses AI (via Ollama and Codellama model) to generate unit tests
- âœ… Stores generated tests in `tests/test_main.cpp`
- âœ… Compiles and runs the tests using `g++`

---

## ğŸ“‚ Project Structure
cpp-unit-test-generator/
â”œâ”€â”€ main.cpp
â”œâ”€â”€ generator.py
â”œâ”€â”€ yaml_prompts/
â”‚ â””â”€â”€ generate_tests.yaml
â”œâ”€â”€ tests/
â”‚ â”œâ”€â”€ functions.cpp
â”‚ â”œâ”€â”€ functions.h
â”‚ â””â”€â”€ test_main.cpp
â””â”€â”€ README.md

 âš™ï¸ How to Run

1. **Install Ollama** and pull the model:
2. llama pull codellama:7b


2. **Generate Unit Tests**:
python generator.py

3. **Compile and Run**:
g++ main.cpp tests/functions.cpp tests/test_main.cpp -o test_program.exe
test_program.exe


## ğŸ“Š Coverage & Improvements

- Test cases are auto-generated covering positive, negative, and edge cases.
- Currently no code coverage tool integrated (can be added using `gcov` later).

## ğŸ™Œ Acknowledgements

- **Ollama**: For running open-source LLMs locally.
- **Keploy API Fellowship**: For providing this hands-on learning opportunity.
GitHub: [https://github.com/toughcodersir](https://github.com/toughcodersir)



